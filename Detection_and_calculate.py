import os
import cv2
import numpy as np
from PIL import Image
import tensorflow as tf
import tensorflow.keras.backend as K
from PIL.ExifTags import GPSTAGS, TAGS
from tensorflow.keras.preprocessing.image import load_img, img_to_array
from tqdm import tqdm
import matplotlib.pyplot as plt

# -------------------------- 2. é¢„æµ‹æ©ç æ¨¡å—ï¼ˆæ¥è‡ªpredict.pyï¼Œç®€åŒ–é€‚é…å•å¼ å›¾åƒï¼‰ --------------------------
# æ¨¡å‹å‚æ•°
IMG_HEIGHT = 912
IMG_WIDTH = 912
CROP_HEIGHT = 228
CROP_WIDTH = 228
BURNED_PIXEL_VALUE = 1
PATH_WEIGHT_NETWORK_1 = "/Users/xiaoyu/Downloads/network_1_weights/checkpoint"  # æ›¿æ¢ä¸ºå®é™…æ¨¡å‹æƒé‡è·¯å¾„
PATH_WEIGHT_NETWORK_2 = "/Users/xiaoyu/Downloads/network_2_weights/checkpoint"  # æ›¿æ¢ä¸ºå®é™…æ¨¡å‹æƒé‡è·¯å¾„

# ===== æ¨¡å‹å®šä¹‰ä¸ä¸€æ¬¡æ€§åŠ è½½ =====
from models import unetpp_level_1, unet_level_2  # éœ€ç¡®ä¿models.pyå­˜åœ¨

_SEG_MODELS = {"l1": None, "l2": None}  # æ¨¡å—çº§å•ä¾‹


def load_model_weights(model, path_weight: str):
    """
    ä»…åŠ è½½æƒé‡åˆ°ç»“æ„ç›¸åŒçš„Kerasæ¨¡å‹ã€‚
    è‹¥ä½ æ”¹æˆSavedModelï¼Œè¯·æ›¿æ¢ä¸ºï¼š
        tf.keras.models.load_model(saved_model_dir, compile=False)
    """
    model.load_weights(path_weight)
    return model


def _build_model_level_1():
    model = unetpp_level_1.create_model()
    # æ¨ç†ç«¯ä¸ compileï¼Œä¸åˆ›å»º optimizerï¼Œé¿å…æ¢å¤æ—¶çš„ optimizer.* å‘Šè­¦
    return load_model_weights(model, PATH_WEIGHT_NETWORK_1)


def _build_model_level_2():
    model = unet_level_2.create_model()
    return load_model_weights(model, PATH_WEIGHT_NETWORK_2)


def load_segmentation_model():
    """
    ä¾› FastAPI å¯åŠ¨æ—¶é¢„çƒ­è°ƒç”¨ã€‚
    è¿”å›å­—å…¸ï¼š{"l1": model1, "l2": model2}
    """
    if _SEG_MODELS["l1"] is None:
        _SEG_MODELS["l1"] = _build_model_level_1()
    if _SEG_MODELS["l2"] is None:
        _SEG_MODELS["l2"] = _build_model_level_2()
    return _SEG_MODELS


# æ¨¡å—å¯¼å…¥æ—¶æ‡’åŠ è½½ï¼ˆä¹Ÿå¯ä¸æå‰åŠ è½½ï¼Œè®© FastAPI åœ¨startupé‡Œè°ƒç”¨ï¼‰
try:
    load_segmentation_model()
except Exception as _e:
    # æƒé‡è·¯å¾„ä¸å­˜åœ¨æ—¶ï¼Œè¿™é‡Œä¸è¦å´©ï¼›ç­‰å®é™…è°ƒç”¨å‰å†æŠ¥é”™å³å¯
    pass

def generate_crops(image_path, output_dir, window_size=228, stride=114,
                   resize_to=(912, 912)):   # â­ æ–°å¢ï¼šç»Ÿä¸€ç¼©æ”¾
    if not os.path.exists(output_dir):
        os.makedirs(output_dir)

    image = cv2.imread(image_path)
    if image is None:
        print(f"[è£å‰ªè­¦å‘Š] æ— æ³•è¯»å–å›¾åƒ: {image_path}")
        return

    if resize_to is not None:
        image = cv2.resize(image, resize_to, interpolation=cv2.INTER_AREA)

    h, w, _ = image.shape
    count = 0
    for y in range(0, h - window_size + 1, stride):
        for x in range(0, w - window_size + 1, stride):
            crop = image[y:y + window_size, x:x + window_size]
            save_path = os.path.join(
                output_dir,
                f"{os.path.splitext(os.path.basename(image_path))[0]}_crop{count}.png"
            )
            cv2.imwrite(save_path, crop)
            count += 1
    print(f"[è£å‰ªå®Œæˆ] å·²ç”Ÿæˆ {count} ä¸ªè£å‰ªå›¾åƒï¼Œä¿å­˜åˆ°: {output_dir}")
    return output_dir


def network_1_prediction(img_path, model_l1=None):
    """å¯¹å•å¼ å›¾åƒè¿›è¡Œä¸€çº§ç½‘ç»œé¢„æµ‹"""
    if model_l1 is None:
        model_l1 = _SEG_MODELS["l1"]
        if model_l1 is None:
            raise RuntimeError("Level-1 æ¨¡å‹å°šæœªåŠ è½½ã€‚è¯·å…ˆè°ƒç”¨ load_segmentation_model()ã€‚")

    # åŠ è½½å¹¶é¢„å¤„ç†å›¾åƒï¼ˆç»Ÿä¸€å¤§å°ï¼‰
    img = load_img(img_path, grayscale=False, target_size=[IMG_HEIGHT, IMG_WIDTH])
    img = img_to_array(img).astype('float32') / 255.0
    img = img.reshape(1, IMG_HEIGHT, IMG_WIDTH, 3)

    # é¢„æµ‹ï¼ˆé™éŸ³ï¼‰
    result = model_l1.predict(img, verbose=0)
    result = result.reshape(IMG_HEIGHT, IMG_WIDTH)
    result = (result > 0.5).astype(np.uint8)  # äºŒå€¼åŒ–
    return result


def network_2_predict_single(crop_path, model_l2=None):
    """äºŒçº§ç½‘ç»œï¼šå•ä¸ª crop çš„é¢„æµ‹ï¼Œè¿”å›äºŒå€¼æ©ç """
    if model_l2 is None:
        model_l2 = _SEG_MODELS["l2"]
        if model_l2 is None:
            raise RuntimeError("Level-2 æ¨¡å‹å°šæœªåŠ è½½ã€‚è¯·å…ˆè°ƒç”¨ load_segmentation_model()ã€‚")

    scale_height, scale_width = 128, 128

    # è¯»å–å¹¶ç¼©æ”¾
    img = load_img(crop_path, target_size=[scale_height, scale_width])
    img = img_to_array(img).astype('float32') / 255.0
    img = img.reshape(1, scale_height, scale_width, 3)

    # é¢„æµ‹
    pred = model_l2.predict(img, verbose=0).reshape(scale_height, scale_width)

    # è¿˜åŸåˆ° 228Ã—228
    pred_resized = cv2.resize(pred, (CROP_WIDTH, CROP_HEIGHT), interpolation=cv2.INTER_NEAREST)

    # äºŒå€¼åŒ–
    pred_resized = (pred_resized >= 0.05).astype(np.uint8)
    return pred_resized


def extract_crop_num(result):
    """æå–åŒ…å«ç‡ƒçƒ§åŒºåŸŸçš„è£å‰ªçª—å£ï¼ˆæŒ‰è¡Œä¼˜å…ˆæ‰«æï¼‰"""
    crop_num = 1
    save_crop_burned_num = []
    for row in np.arange(0, IMG_HEIGHT, CROP_HEIGHT):
        for col in np.arange(0, IMG_WIDTH, CROP_WIDTH):
            crop_window = result[row:row + CROP_HEIGHT, col:col + CROP_WIDTH]
            if crop_window.any():
                save_crop_burned_num.append(crop_num)
            crop_num += 1
    return save_crop_burned_num


def merge_mask_tiles_to_png(
    crop_dir,
    output_path,
    window_size=228,
    stride=114,
    resize_to=(912, 912),
    reference_image=None
):
    """
    å°†è£å‰ªé¢„æµ‹çš„æ©ç å—ç›®å½•æ‹¼å›æ•´å›¾ã€‚
    å‚æ•°:
        crop_dir: æ©ç å—æ‰€åœ¨æ–‡ä»¶å¤¹
        output_path: è¾“å‡ºåˆå¹¶æ©ç çš„è·¯å¾„
        window_size, stride, resize_to: ä¸ generate_crops() ç›¸åŒ
        reference_image: è‹¥æŒ‡å®šï¼Œå°†è¾“å‡ºç¼©æ”¾ä¸ºè¯¥å›¾çš„åŸå§‹å¤§å°
    """
    files = sorted(
        [f for f in os.listdir(crop_dir) if f.endswith(".png")],
        key=lambda x: int(os.path.splitext(x)[0].split("_crop")[-1])
    )

    if not files:
        print(f"[merge] æ²¡æ‰¾åˆ°æ©ç å—: {crop_dir}")
        return None

    sample = cv2.imread(os.path.join(crop_dir, files[0]), cv2.IMREAD_UNCHANGED)
    h_tile, w_tile = sample.shape[:2]

    full_h, full_w = resize_to
    ny = (full_h - window_size) // stride + 1
    nx = (full_w - window_size) // stride + 1

    merged = np.zeros((full_h, full_w), dtype=np.float32)
    weight = np.zeros_like(merged)

    count = 0
    for j in range(ny):
        for i in range(nx):
            if count >= len(files):
                break
            path = os.path.join(crop_dir, files[count])
            tile = cv2.imread(path, cv2.IMREAD_GRAYSCALE).astype(np.float32) / 255.0
            y, x = j * stride, i * stride
            merged[y:y+window_size, x:x+window_size] += tile
            weight[y:y+window_size, x:x+window_size] += 1.0
            count += 1

    weight[weight == 0] = 1.0
    merged /= weight
    merged = (merged > 0.5).astype(np.uint8) * 255

    # è‹¥æä¾›äº†å‚è€ƒå›¾ï¼Œåˆ™ resize åˆ°åŸå§‹å›¾å¤§å°
    if reference_image and os.path.exists(reference_image):
        ref = cv2.imread(reference_image)
        ref_h, ref_w = ref.shape[:2]
        merged = cv2.resize(merged, (ref_w, ref_h), interpolation=cv2.INTER_NEAREST)

    # å°†ç™½è‰²(255)å˜ä¸ºçº¢è‰²
    mask_color = np.zeros((*merged.shape, 3), dtype=np.uint8)
    mask_color[merged == 255] = [0, 0, 255]  # BGR çº¢
    os.makedirs(os.path.dirname(output_path), exist_ok=True)

    # å¦‚æœä½ åé¢è¦æŒ‰RGBè¯»å–ç»Ÿè®¡â€œçº¢è‰²â€ï¼Œå°±æŠŠå½©è‰²å›¾å†™ç›˜ï¼š
    cv2.imwrite(output_path, mask_color)  # â† æ”¹æˆä¿å­˜å½©è‰²
    print(f"[merge] å·²ç”Ÿæˆå®Œæ•´ã€å½©è‰²ã€‘æ©ç å›¾: {output_path}")
    return output_path

# =================== Modified predict_mask ===================
def predict_mask(corrected_img_path, save_mask_dir, models: dict | None = None):
    """
    å¯¹çŸ«æ­£å›¾åƒç”Ÿæˆæ¯ä¸ª crop çš„æ©ç ï¼ˆRGB çº¢è‰²åŒºåŸŸä¸ºç«ç¾ï¼‰ã€‚
    models å¯é€‰ï¼š{"l1": model1, "l2": model2}
    """
    models = models or _SEG_MODELS  # é»˜è®¤ç”¨æ¨¡å—çº§å•ä¾‹
    if models.get("l1") is None or models.get("l2") is None:
        # å°è¯•åŠ è½½ï¼ˆå¦‚æœä¹‹å‰æ²¡åŠ è½½ï¼‰
        load_segmentation_model()

    # ï¼ˆå¯é€‰ï¼‰ä¸€çº§ç½‘ç»œç²—é¢„æµ‹ â€”â€” ç›®å‰ä»…ç”¨äºè°ƒè¯•/å¯è§†åŒ–ï¼Œä¸åšç­›é€‰
    try:
        _ = network_1_prediction(corrected_img_path, model_l1=models.get("l1"))
    except Exception as e:
        print(f"[è­¦å‘Š] ä¸€çº§ç½‘ç»œé¢„æµ‹å¤±è´¥ï¼ˆä¸å½±å“äºŒçº§ï¼‰ï¼š{e}")

    # ç”Ÿæˆ crop
    crop_dir = os.path.join(os.path.dirname(corrected_img_path), "crops")
    os.makedirs(crop_dir, exist_ok=True)
    generate_crops(corrected_img_path, crop_dir, window_size=CROP_HEIGHT, stride=CROP_HEIGHT // 2)

    # äºŒçº§ç½‘ç»œé€å—é¢„æµ‹
    label_dir = os.path.join(save_mask_dir, "label_crops")
    os.makedirs(label_dir, exist_ok=True)

    crop_files = sorted([
        os.path.join(crop_dir, f)
        for f in os.listdir(crop_dir)
        if f.lower().endswith((".png", ".jpg", ".jpeg", ".webp"))
    ])

    print(f"æ£€æµ‹åˆ° {len(crop_files)} ä¸ªè£å‰ªå—ï¼Œå¼€å§‹ç”Ÿæˆæ©ç ...")

    for i, crop_path in enumerate(crop_files):
        pred_mask = network_2_predict_single(crop_path, model_l2=models.get("l2"))

        mask_bin = (pred_mask.astype(np.uint8)) * 255  # 0 or 255

        mask_name = f"mask_{os.path.basename(crop_path)}"
        mask_path = os.path.join(label_dir, mask_name)
        cv2.imwrite(mask_path, mask_bin)

        if (i + 1) % 50 == 0 or i == len(crop_files) - 1:
            print(f"[{i + 1}/{len(crop_files)}] ä¿å­˜æ©ç è‡³: {mask_path}")

    print(f"âœ… æ‰€æœ‰æ©ç å·²ä¿å­˜è‡³: {label_dir}")
    return label_dir


# -------------------------- 3. çº¢è‰²é¢ç§¯è®¡ç®—æ¨¡å—ï¼ˆæ¥è‡ªcalculate_Area.pyï¼‰ --------------------------
import os
import numpy as np
from PIL import Image

def calculate_red_area_image(mask_path, area):
    """
    è®¡ç®—å•å¼ çº¢è‰²æ©ç å›¾ï¼ˆmerged.pngï¼‰ä¸­çº¢è‰²åŒºåŸŸçš„é¢ç§¯å æ¯”ã€‚
    å‚æ•°:
        mask_path: merged.png æ–‡ä»¶è·¯å¾„
        area: å®é™…åœ°é¢æ€»é¢ç§¯ï¼ˆå¹³æ–¹ç±³ï¼‰
    è¿”å›:
        red_ratio: çº¢è‰²å æ¯” (0~1)
        red_area: è¿‡ç«é¢ç§¯ (å¹³æ–¹ç±³)
    """
    if not os.path.exists(mask_path):
        print(f"[é”™è¯¯] æ‰¾ä¸åˆ°æ©ç æ–‡ä»¶: {mask_path}")
        return 0, 0

    # æ‰“å¼€å›¾åƒå¹¶è½¬ä¸º RGB
    img = Image.open(mask_path).convert('RGB')
    img_array = np.array(img)

    # æå– R/G/B é€šé“
    r, g, b = img_array[:, :, 0], img_array[:, :, 1], img_array[:, :, 2]

    # çº¢è‰²åƒç´ åˆ¤æ–­ï¼ˆR=255, G=0, B=0ï¼‰
    red_pixels = (r == 255) & (g == 0) & (b == 0)

    total_red = np.sum(red_pixels)
    total_pixels = img_array.shape[0] * img_array.shape[1]

    if total_pixels == 0:
        return 0, 0

    red_ratio = total_red / total_pixels
    red_area = red_ratio * area

    print(f"âœ… æ©ç ç»Ÿè®¡å®Œæˆï¼šçº¢è‰²å æ¯” {red_ratio:.4%}ï¼Œè¿‡ç«é¢ç§¯çº¦ {red_area:.2f} mÂ²")
    return red_ratio, red_area


# -------------------------- ä¸»æµç¨‹ï¼šæ•´åˆä¸‰ä¸ªæ¨¡å— --------------------------
if __name__ == "__main__":
    # é…ç½®è·¯å¾„
    original_img_path = "/Users/xiaoyu/Downloads/forest-fire-damage-mapping-main/sample_data/sample_location_1_data/Orig/orig.JPG"  # åŸå§‹æ— äººæœºå›¾åƒè·¯å¾„
    mask_dir = "./sample_data/sample_location_1_data/Label"  # æ©ç å›¾ä¿å­˜ç›®å½•

    area = 2000

    # é¢„æµ‹æ©ç ï¼ˆé€ cropï¼‰
    os.makedirs(mask_dir, exist_ok=True)
    mask_path = predict_mask(original_img_path, mask_dir)

    merged_path = merge_mask_tiles_to_png(
        crop_dir="sample_data/sample_location_1_data/Label/label_crops",
        output_path="uploads/merged.png",
        window_size=228,
        stride=114,
        resize_to=(912, 912),
        reference_image="uploads/mission_1002.jpg"
    )

    # è®¡ç®—çº¢è‰²åƒç´ æ•°ï¼ˆæ‰€æœ‰æ©ç å—çš„çº¢åƒç´ ç´¯è®¡ï¼‰
    red_ratio, red_area = calculate_red_area_image("uploads/merged.png", area)

    print(f"ğŸ”¥ ä¼°è®¡ç‡ƒçƒ§é¢ç§¯ï¼š{red_area:.2f} m^2 ï¼ˆåŸºäºé€è§†çŸ«æ­£ä¸åœ°é¢å››è¾¹å½¢æ ‡å®šï¼‰")
    print(f"ï¼ˆæ•´å¹…å›¾åœ°é¢è¦†ç›–â‰ˆ {area} m^2ï¼›çº¢è‰²åƒç´ å æ¯”â‰ˆ {red_ratio:.2%}ï¼‰")